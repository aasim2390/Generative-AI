# üöÄ LangChain LCEL Chaining Method ‚Äì Explained with Examples

---

## 1Ô∏è‚É£ What is LCEL?

**LangChain Expression Language (LCEL)** is a modern way to **connect AI components** in a clean, readable workflow.

 - Uses the **pipe operator** `|` to pass data from one step to another.
 - Makes AI workflows **flexible, reusable, and easy to read.**
 - Automatically converts normal functions, templates, or dictionaries into components **(type coercion).**
 - Best for **simpler chains**, can be used inside bigger systems like LangGraph.

Think of it like:
- **Recipe** ‚Üí template
- **Prep station** ‚Üí RunnableLambda
- **Chef** ‚Üí LLM
- **Conveyor belt** ‚Üí pipe `|`
- **Team of chefs** ‚Üí RunnableParallel / RunnableSequential

## 2Ô∏è‚É£ LCEL Key Components

| Component            | What it does                             | Analogy                                                |
| -------------------- | ---------------------------------------- | ------------------------------------------------------ |
| **PromptTemplate**   | Defines instructions with placeholders   | Recipe card                                            |
| **RunnableLambda**   | Wraps a function to work in LCEL         | Prep station                                           |
| **Pipe**             | Passes output from one step to the next  |  Conveyor belt                                         |
| **RunnableSequence** | Runs steps **one after another**         | Line of chefs working sequentially                     |
| **RunnableParallel** | Runs **multiple steps at the same time** | Multiple chefs cooking at once                         |
| **StrOutputParser**  | Cleans and formats AI output             | Plate the dish nicely                                  |

## 3Ô∏è‚É£ LCEL Use Cases

| Use Case           | Example                                                      |
| ------------------ | ------------------------------------------------------------ |
| Summarization      | Summarize articles, homework notes, essays                   |
| Translation        | English ‚Üí French/Spanish/Japanese                            |
| Sentiment Analysis | Detect if a product review is positive, negative, or neutral |
| Content Generation | Write jokes, stories, or blog posts                          |
| Parallel Tasks     | Run summary, translation, sentiment at the same time         |
| Reusable Pipelines | Reuse the chain for multiple inputs                          |


**Example:**
- Input = "AI can summarize text, translate, and write poems."
- Parallel output = summary, translation, sentiment, joke

## 4Ô∏è‚É£ Sequential LCEL Example (Step by Step)

### Step 1: Imports
```python
from langchain.prompts import PromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.chains import RunnableLambda, RunnableSequence
from langchain.output_parsers import StrOutputParser
```

### Step 2: LLM Setup
```python
llm = ChatOpenAI(temperature=0.7, model_name="gpt-3.5-turbo")

```

### Step 3: Prompt Templates
```python
template1 = PromptTemplate(input_variables=["text"], template="Summarize this: {text}")
template2 = PromptTemplate(input_variables=["text"], template="Translate this into French: {text}")
template3 = PromptTemplate(input_variables=["text"], template="Analyze sentiment: {text}")

```

### Step 4: Wrap Templates in RunnableLambda
```python
step1 = RunnableLambda(lambda x: template1.format_prompt(text=x))
step2 = RunnableLambda(lambda x: template2.format_prompt(text=x))
step3 = RunnableLambda(lambda x: template3.format_prompt(text=x))

```

### Step 5: Create Sequential Chain
```python
chain = RunnableSequence([step1 | llm | StrOutputParser(),
                          step2 | llm | StrOutputParser(),
                          step3 | llm | StrOutputParser()])

```

### Step 6: Run Chain

```python
input_text = "AI can summarize text, translate, and write poems."
results = chain(input_text)
print(results)

```

**Sequential Flow:**
> ***Input ‚Üí Summary ‚Üí Translation ‚Üí Sentiment ‚Üí Output***

## 5Ô∏è‚É£ Parallel LCEL Example

```python
tasks = RunnableParallel({
    "summary": step1 | llm | StrOutputParser(),
    "translation": step2 | llm | StrOutputParser(),
    "sentiment": step3 | llm | StrOutputParser()
})

results = tasks(input_text)
print(results)

```
**Parallel Flow:**
> ***Input ‚Üí Summary, Translation, Sentiment (all at the same time) ‚Üí Output***

## 6Ô∏è‚É£ LCEL Advantages

- **Clear flow of data** using pipes `|`
- **Sequential or parallel execution**
- **Reusable and composable chains**
- **Auto type conversion** (functions ‚Üí runnable components)
- **Async and streaming support**
- Perfect for LLMs and Generative AI tasks

## 7Ô∏è‚É£ Memorable Analogy

|     Concept      |               Analogy                  |              
| ---------------- | -------------------------------------- | 
| PromptTemplate   | Recipe card                            | 
| RunnableLambda   | Prep station                           | 
| Pipe             | Conveyor belt                          | 
| RunnableSequence | Line of chefs, one after another       | 
| RunnableParallel | Team of chefs working at the same time | 
| LLM              | Chef cooking the dish                  | 
| StrOutputParser  | Plating the dish nicely                | 
| Input            | Raw ingredients                        | 
| Output           | Finished meal                          | 


### ‚úÖ Quick Reference Cheat Sheet

LCEL Steps

1. Create PromptTemplate
2. Wrap in RunnableLambda
3. Connect with pipe |
4. Use RunnableSequence (sequential) or RunnableParallel (parallel)
5. Send input ‚Üí get output

### Example
```python

step1 | llm | StrOutputParser()  # Sequential

{"summary": step1, "sentiment": step3}  # Parallel

```

