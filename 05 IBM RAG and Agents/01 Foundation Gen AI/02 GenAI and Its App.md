# 🌍 Introduction to Foundation Models & LLMs  

## 🚀 Rise of Large Language Models (LLMs)  
- Examples: **ChatGPT**, **GPT-4**  
- Applications: writing, planning, enterprise productivity  
- Part of a broader class called **Foundation Models**  

---

## 🏛 What are Foundation Models?  
- Term coined by **Stanford researchers**  
- New paradigm:  
  - Old way → train **many task-specific models**  
  - New way → **one large model** → adapted to many tasks  
- **Trained on huge datasets (terabytes of unstructured data)**  

---

## 🔄 Why are Foundation Models Generative?  
- Core task: **predict the next word** in a sequence  
  - e.g., *“No use crying over spilled … [milk]”*  
- This **generation ability** = part of **Generative AI**  
- With **tuning (small labeled data)** → can perform:  
  - Classification  
  - Named Entity Recognition  
  - Other NLP tasks  

---

## 🛠 Ways to Use Foundation Models  
1. **Tuning**  
   - Add a small labeled dataset → specialize the model  
2. **Prompting (Prompt Engineering)**  
   - Ask the model questions in natural language  
   - Example: “Is this sentence positive or negative?”  

---

## ✅ Advantages  
1. **High performance** → trained on massive data  
2. **Productivity gains** → less labeled data needed  
3. **Versatility** → works in low-data environments  

---

## ⚠️ Disadvantages  
1. **Compute Costs**  
   - Expensive to train (billions of parameters)  
   - Expensive to run (multiple GPUs for inference)  
2. **Trustworthiness Issues**  
   - Data scraped from internet → bias, toxicity, misinformation  
   - Often unclear what datasets were used  

---

## 💡 IBM’s Contributions & Innovations  
- **Efficiency & trustworthiness improvements**  
- Applications across domains:  
  - **Language:** Watson Assistant, Watson Discovery  
  - **Vision:** Maximo Visual Inspection  
  - **Code:** Project Wisdom with Red Hat (Ansible code models)  
  - **Chemistry:** Moleformer (molecule discovery for therapeutics)  
  - **Climate:** Earth science foundation models (geospatial data for climate research)  

---

## 🎯 Key Takeaways  
- **Foundation Models = a new AI paradigm**  
- LLMs are just **one example** (text domain)  
- Benefits: performance, adaptability, productivity  
- Challenges: cost, trust, transparency  
- IBM + industry are working to **improve efficiency & trust** while expanding to **multiple domains**  
