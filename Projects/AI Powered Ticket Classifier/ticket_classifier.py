# ============================================
# üß† AI-Powered Ticket Classifier (LangChain)
# Author: Mohammad Asim
# Description: Routes IT support tickets (Login Issue, Bug, Data Extraction)
# ============================================

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from dotenv import load_dotenv, find_dotenv
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from langchain_community.utils.math import cosine_similarity
from pydantic import BaseModel, Field
from pprint import pprint
import numpy as np
import os
import pickle

# ============================================
# üîπ Step 1: Load environment variables
# ============================================
dotenv_path = find_dotenv(usecwd=True)
if dotenv_path:
    load_dotenv(dotenv_path)
else:
    raise FileNotFoundError("‚ö†Ô∏è .env file not found!")

# ============================================
# üîπ Step 2: Define output structure
# ============================================
class OutputStructure(BaseModel):
    user_request: str = Field(description="Request received from user")
    request_category: str = Field(description="Either of these : [Login Issue, Bug, Data Extraction]")
    response: str = Field(description="Response generated by the LLM Model")

# ============================================
# üîπ Step 3: Initialize LLM model
# ============================================
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.8)

# ============================================
# üîπ Step 4: Helper function to create prompts
# ============================================
def make_prompt(system_text, user_text):
    return ChatPromptTemplate.from_messages([
        ("system", system_text),
        ("user", user_text)
    ])

# ============================================
# üîπ Step 5: Define prompt templates & chains
# ============================================

prompt_login_issue = make_prompt(
    "You are a helpful IT assistant who resolves login-related issues.",
    "Request: {user_request}. Respond in JSON with 'user_request', 'request_category', and 'response'. "
    "'request_category' must be one of [Login Issue, Bug, Data Extraction]. "
    "'response' should be under 200 words."
)
chain_login_issue = prompt_login_issue | llm | JsonOutputParser(pydantic_object=OutputStructure)

prompt_bug = make_prompt(
    "You are a helpful assistant who helps in bug logging and tracking.",
    """Understand the bug request mentioned below and summarize it for engineering team to work.
    <user_request>{user_request}</user_request>
    Respond in JSON with 'user_request', 'request_category', and 'response'. 
    'request_category' must be one of [Login Issue, Bug, Data Extraction]. 
    'response' should be under 200 words."""
)
chain_bug = prompt_bug | llm | JsonOutputParser(pydantic_object=OutputStructure)

prompt_data_extraction = make_prompt(
    "You are a helpful assistant who helps extract data from multiple sources.",
    """Understand the data extraction request mentioned below and suggest the best way to extract data. 
    <user_request>{user_request}</user_request>
    Respond in JSON with 'user_request', 'request_category', and 'response'. 
    'request_category' must be one of [Login Issue, Bug, Data Extraction]. 
    'response' should be under 200 words."""
)
chain_data_extraction = prompt_data_extraction | llm | JsonOutputParser(pydantic_object=OutputStructure)

# ============================================
# üîπ Step 6: Define fallback chain
# ============================================
def fallback_chain(user_request):
    return {
        "user_request": user_request,
        "request_category": "Unclassified",
        "response": "I could not confidently categorize this request. Forwarding to manual support."
    }

# ============================================
# üîπ Step 7: Setup router data
# ============================================
router_chains = [chain_login_issue, chain_bug, chain_data_extraction]
chain_descriptions = ["login issue", "bug logging and tracking", "data extraction"]

embedding_model = OpenAIEmbeddings()

# --- Normalize helper ---
def normalize(vec):
    return vec / np.linalg.norm(vec)

# --- Load or cache embeddings ---
if os.path.exists("chain_embeds.pkl"):
    with open("chain_embeds.pkl", "rb") as f:
        chain_embeds = pickle.load(f)
else:
    raw_embeds = embedding_model.embed_documents(chain_descriptions)
    chain_embeds = [normalize(e) for e in raw_embeds]
    with open("chain_embeds.pkl", "wb") as f:
        pickle.dump(chain_embeds, f)

# ============================================
# üîπ Step 8: Router function
# ============================================
def route_request(user_request: str, confidence_threshold: float = 0.75):
    # Generate embedding for user query
    query_emb = normalize(embedding_model.embed_query(user_request))
    
    # Compute cosine similarity
    similarity_scores = cosine_similarity([query_emb], chain_embeds)[0]
    best_index = int(np.argmax(similarity_scores))
    best_score = float(similarity_scores[best_index])
    best_chain_name = chain_descriptions[best_index]
    
    print(f"üîç Similarity Scores: {similarity_scores}")
    print(f"‚úÖ Best Match: {best_chain_name} | Confidence: {best_score:.3f}")
    
    # Confidence-based routing
    if best_score < confidence_threshold:
        print("‚ö†Ô∏è Low confidence ‚Äî triggering fallback chain.")
        return fallback_chain(user_request)
    
    selected_chain = router_chains[best_index]
    response = selected_chain.invoke({"user_request": user_request})
    
    return {
        "selected_chain": best_chain_name,
        "confidence": best_score,
        "response": response
    }

# ============================================
# üîπ Step 9: Test Run
# ============================================

if __name__ == "__main__":
    # Test examples
    test_requests = [
        "I can‚Äôt log in to my Outlook account.",
        "The site shows a 404 error after clicking submit.",
        "I need to extract delivery dates from the business team‚Äôs product list."
    ]
    
    for req in test_requests:
        print("\nüßæ New Ticket:", req)
        result = route_request(req)
        pprint(result)
        print("-" * 80)
